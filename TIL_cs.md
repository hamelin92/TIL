Computer Science

## 1. Data Structure

### 1-1. 배열 Array



### 1-2. 연결 리스트 Linked List

- 데이터, 노드를 저장할 때 다음 순서의 자료의 위치를 포함시키는 자료 구조
- 노드(데이터 + 다음 노드를 가리키는 포인터) -> 노드2 -> 노드3 -> ...
- 단순 연결 리스트 : 가장 단순한 형태의 연결 리스트.
- 이중 연결 리스트 : 다음 노드에 대한 참조와 이전 노드에 대한 참조를 포함
- 원형 연결 리스트 : 단순연결리스트에서 마지막 원소가 Null 대신 처음 원소를 가리키게 한다.
- 시간복잡도
  - 삽입 : O(1)
  - 삭제 : O(1)
  - 탐색 : O(k) ~ O(N)
- 장점
  - 삽입과 삭제가 O(1)에 이루어진다
  - 삽입과 삭제를 할때마다 동적으로 연결리스트의 크기가 결정, 처음부터 큰 공간 할당할 필요 X
  - 메모리관리가 용이
- 단점
  - Random Access 배열처럼 index를 통한 탐색 X
  - 탐색이 O(N) 걸린다. Head부터 Tail까지 모두 탐색시
  - 삽입과 삭제가 왼쪽에서 이루어지지 않을 경우 탐색부터 해야한다.
- 파이썬에서의 연결 리스트
  - 리스트 자체에서 연결리스트에서 필요한 기능을 모두 지원한다!

### 1-3. Array & Array List & Linked List



### 1-4. Stack

가장 마지막에 들어온 데이터를 제일 먼저 출력하는 자료 구조. 바닥이 막힌 상자에 데이터를 위로 쌓고 위에서부터 내리는 형태로 이해할 수 있다.

- Stack - 파이썬 리스트로 구현 가능
  - 후입선출 LIFO Last In First Out

- 연산
  - Push 입력 - append() (리스트의 맨 뒤에 들어간다.) - O(1)
  - Pop 출력 - pop() ( 리스트의 맨 뒤 원소를 빼내고 그 원소를 반환한다.) - O(1)
  - Peek 조회 - top - 인덱스 [-1]을 사용.


### 1-4-2. Queue

제일 먼저 들어온 데이터를 제일 먼저 출력하는 자료구조. 양쪽이 뻥 뚫린 통로에 한쪽에서 자료를 밀어 넣고 그 반대쪽으로 자료가 나오는 형태로 이해할 수 있다.

- Queue - 파이썬에서 연결 리스트로 구현

  - 선입선출 FiFo First In First Out
- 연산

  - Enqueue 입력 - 간단하게 insert(0, arr) - O(N) 로 구현 ( 반대 방향으로는 append) 하지만 비효율

  - Dequeue 출력 - 간단하게 pop()으로 구현 ( 반대 방향으로는 pop(0) - O(N))
- Queue - deque 양방향 큐
  - collections 모듈에 존재, double- ended queue의 약자로 양방향에서 입출력 가능
  - popleft()로 pop(0) 대체 가능 - O(1)
  - appendleft()로 insert 대체 가능 - O(1)
  - 무작위 접근의 복잡도 O(N),  i 번째 데이터에 접근하려면 i번 탐색 필요
- Queue - queue
  - queue 모듈의 Queue 클래스 사용
  - 주로 멀티 쓰레딩 환경에서 사용되며 내부적으로 라킹을 지원
  - deque와 달리 방향성 X , 똑같이 데이터에 접근하는데는 O(N)
  - put(x) 데이터 추가 O(1)
  - get(x) 데이터 삭제 O(1)

















### 1-5. 힙 Heap

- 우선순위 큐 Queue
  - 큐에 우선순위 개념을 도입, 우선순위가 높은 것부터 삭제
  - 우선순위 큐는 배열, 연결리스트, 힙으로 구현
  - 힙 삽입 -> O(log N), 삭제 -> O(log N)  
- 힙 - 완전 이진 트리의 일종, 무언가를 차곡차곡 쌓아올린 더미라는 의미
  - 반정렬 상태, 중복된 값 허용 (이진탐색트리는 중복X)
- 힙 종류
  - 최대 힙 - 부모 노드의 키 값이 자식 노드의 키 값보다 크거나 같은 완전 이진 트리
  - 최소 힙 - 부모 노드의 키 값이 자식 노드의 키 값보다 작거나 같은 완전 이진 트리
  - ![img](TIL_cs.assets/17084F504DA9895214.png)
- 데이터 처리
  - 삽입
    -  가장 끝의 자리에 노드 삽입
    - 그 노드와 부모 노드를 비교, 규칙에 맞으면 그대로 두고 그렇지 않으면 부모와 교환
    - 맞을 때까지 반복

  - 삭제
    - 루트 노드를 제거 (최대힙은 최대값, 최소힙은 최소값)
    - 루트 자리에 가장 마지막 노드를 삽입
    - 올라간 노드와 그의 자식노드 비교
    - 조건에 만족하면 그대로 두고 그렇지 않으면 자식과 교환
- heapq 모듈 - 이진 트리 기반의 최소힙 자료구조 제공.
  - heappush(x) 원소 추가 O(logN)
  - heappop() 삭제 O(logN)
  - heapify(x) 리스트 x를 즉각 heap으로 변환 O(N)






































### 1-6. 트리 Tree

- 순회 방식
  - 전위 순회 (pre-order) - 각 루트를 순차적으로 먼저 방문
  - 중위 순회 (in-order) - 왼쪽 하위 트리를 방문 후 루트를 방문, 그후 오른쪽
  - 후위 순회 (post-order) - 왼쪽 하위 트리부터 하위를 모두 방문 후 루트를 방문
  - 레벨 순회 (level-order) - 루트부터 계층 별로 방문

### 1-7. 이진탐색 트리

이진탐색 + 연결리스트

이진탐색 : 탐색에 소요되는 시간복잡도는 O(logN), 삽입삭제 불가능

연결리스트: 삽입, 삭제의 시간복잡도는 O(1), 탐색 시간복잡도  O(N)

노드의 자식이 2개 이하

노드의 왼쪽자식은 부모보다 작고 오른쪽은 크다.

중복 X - 중복은 노드에 count 값을 주는 방법으로 처리하는게 좋다.

inorder 중위순회 방식 ( 왼 루트 오) - 정렬된 순서를 읽을 수 있다.

BST binary search tree 핵심 연산

- 검색
- 삽입
- 삭제
- 트리생성
- 트리삭제

시간복잡도

- 균등 트리 : 노드 개수가 N개일때 O(log N)
- 편향트리 : 노드 개수가 N개일때 O(N)
- 삽입 검색 삭제 시간 복잡도는 트리의 depth에 비례

삭제의 3가지 case

1. 자식이 없는 leaf노드일 때 -> 그냥 삭제
2. 자식이 1개인 노드일 때 -> 지워진 노드에 자식을 올리기
3. 자식이 2개인 노드일 때 -> 오른쪽 자식 노드에서 가장 작은 값 or 왼쪽 자식에서 가장 큰 값 올리기

편향된 트리 ( 정렬된 상태 값으로 트리로 만들면 한쪽으로만 뻗음)는 시간 복잡도가 O(N)이므로 트리를 사용할 이유가 없음. 이를 바로 잡도록 도와주는 개선 트리 AVL Tree, RedBlack Tree







### 1-8. 해시 Hash

EX ) 해시 태그, 

데이터를 효율적으로 관리하기 위해, 임의의 길이 데이터를 고정된 길이의 데이터로 매핑하는 것

해시함수를 구현하여 데이터 값을 해시 값으로 매핑한다. 

결국 데이터가 많아지면, 다른 데이터가 같은 해시 값으로 충돌나는 현상이 발생함.

collision 현상



해시테이블을 쓰는 이유

적은 자원으로 많은 데이터를 효율적으로 관리하기 위해

하드디스크나 클라우드에 존재하는 무한한 데이터들을 유한한 개수의 해시값으로 매핑하면서 작은 메모리로도 프로세스 관리가 가능해짐.



언제나 동일한 해시값 리턴, index를 알면 빠른 데이터 검색이 가능해짐

해시테이블의 시간복잡도 O(1) - 이진 탐색트리는 O(log N)



충돌 문제 해결

1. 체이닝 : 연결리스트로 노드를 계속 추가해 나가는 방식(제한 없이 계속 연결 가능, but 메모리 문제)
2. open Addressing : 해시 함수로 얻은 주소가 아닌 다른 주소에 데이터를 저장할 수 있도록 허용(해당 키값에 저장되어 있으면 다음 주소에 저장)
3. 선형 탐사 : 정해진 고정 폭으로 옮겨 해시값의 중복을 피함
4. 제곱 탐사: 정해진 고정폭을 제곱수로 옮겨 해시값의 중복을 피함
5. 이중해싱(double hashing) : 탐사할 해시값의 규칙성 없애서 충돌을 방지.



- 해시 함수-> 
  - 해시테이블의 크기가 m이면 임의의 키 값을 임의의 해시값에 1/m의 확률로 매핑하는 것이 좋다. 즉 
  - division method
    - 숫자로 된 키를 해시테이블 크기 m으로 나눈 나머지를 해시값으로 반환
    - m은 보통 prime number를 쓰고 2의 제곱수와 멀도록 함.
    - 간단하면서도 빠른 연산이 가능하지만 해시함수의 특성에 의해 해시테이블의 크기가 결정됨.
  - multiplication method
    - 숫자로 된 키가 k 이고 A는 0과 1사이의 실수일 때 k와 A를 곱한 값의 소수점자리를 이용.
    - 소수점에 m만큼 곱한 값을 사용한다. m은 보통 큰 2의 제곱수로 정함
  - universal hasing
    - 다수의 해시함수를 만들고 이들중 무작위로 선택해 해시값을 만드는 방법
    - 무작위로 뽑은 해시함수에 대해 임의의 키값이 임의의 해시값에 매핑될 확률이 1/m이 되어야 한다.
    - 특정 조건의 해시함수 집합은 위 조건을 만족시킬 수 있음이 증명되어있다.



- 구현

  - 파이썬에서는 dictionary 타입이 해시 테이블과 같은 구조이다.

  - 여러 키에 해당하는 주소가 동일할 경우 충돌 collision을 해결하기 위한 별도의 자료구조가 필요. (충돌 해결 알고리즘)

  - 미리 해시테이블만큼의 배열을 생성해서 쓰기때문에 공간을 많이 사용.

  - hashlib 로 sha 해쉬함수 사용 가능

  - ```python
    import hashlib 
    #sha1 은 해쉬값의 크기를 160으로 고정하는 알고리즘
    data = 'test'.encode() 
    hash_object = hashlib.sha1() 
    hash_object.update(data) 
    hex_dig = hash_object.hexdigest() 
    print(hex_dig) 
    
    data2 = 'hello world'.encode() 
    hash_object2 = hashlib.sha1() 
    hash_object2.update(data2) 
    hex_dig2 = hash_object2.hexdigest() 
    print(hex_dig2)
    ```

  - sha-256은 해쉬값의 크기를 256으로 늘린 알고리즘.

- 리스트로 해시테이블 구현

- ```python
  #리스트로 구현한 길이가 8인 해시 테이블 클래스
  class HashTable: 
      def __init__(self): 
          self.hash_table = list([0 for i in range(8)]) 
          
      def hash_function(self, key): 
          return key % 8 
      
      def insert(self, key, value): 
          hash_value = self.hash_function(hash(key)) 		         
          self.hash_table[hash_value] = value      
          
      def read(self, key): 
          hash_value = self.hash_function(hash(key)) 
          return self.hash_table[hash_value] 
      
      def print(self): print(self.hash_table)
  
          
  출처: https://davinci-ai.tistory.com/19 [DAVINCI - AI]
  ```

- 

- 

- 









































- 

- 

  ```python
  
  
  class HashTable: 
      def __init__(self): 
          self.hash_table = list([0 for i in range(8)]) 
          
      def hash_function(self, key): 
  # Custom Hash Function 
  		return key % 8 
  	def insert(self, key, value):
          gen_key = hash(key) 
          hash_value = self.hash_function(gen_key) 
          if self.hash_table[hash_value] != 0: 
              # 해당 hash value index를 이미 사용하고 있는 경우(충돌 시) 
              for i in range(len(self.hash_table[hash_value])): 
                  # 이미 같은 키 값이 존재하는 경우 -> value 교체 
                  # 이때 0은 key, 1은 value값이 존재하는 인덱스 
                  if self.hash_table[hash_value][i][0] == gen_key: 
                      self.hash_table[hash_value][i][1] = value 
                      return 
                  # 같은 키 값이 존재하지 않는 경우에는 [key, value]를 해당 인덱스에 삽입 
                  self.hash_table[hash_value].append([gen_key, value]) 
              else: 
                  # 해당 hash_value를 사용하고 있지 않는 경우 
                  self.hash_table[hash_value] = [[gen_key, value]] 
  	def read(self, key):
          gen_key = hash(key)
          hash_value = self.hash_function(gen_key)
          if self.hash_table[hash_value] != 0:
              # 해당 해쉬 값 index에 데이터가 존재할 때,
              for i in range(len(self.hash_table[hash_value])):
                  if self.hash_table[hash_value][i][0] == gen_key:
                      # 키와 동일할 경우 -> 해당 value return 
                      return self.hash_table[hash_value][i][1] 
                  # 동일한 키가 존재하지 않으면 None return 
                  return None 
          else: 
              # 해당 해쉬 값 index에 데이터가 없을 때, 
              return None 
              
      def print(self): print(self.hash_table)
  
  출처: https://davinci-ai.tistory.com/19 [DAVINCI - AI]
  ```

- 



### 1-9. 트라이 Trie

문자열에서 검색을 빠르게 도와주는 자료 구조

이진탐색트리에서 문자열 길이 M을 탐색하려면 O(M log N)의 시간복잡도

하지만 트라이를 활용하면 O(M)으로 가능하다.



### 1-10. B Tree & B+ Tree

- B트리 : 이진트리를 확장해서 더 많은 수의 자식을 가질 수 있게 일반화한 트리

  - 노드의 자료수가 N이면 자식수는 N+1이어야 함
  - 각 노드의 자료는 정렬된 상태여야 함
  - 루트노드는 적어도 2개 이상의 자식을 가져야함
  - 루트 노드를 제외한 모든 노드는 적어도 M/2개의 자료를 가지고 있어야함.
  - 외부노드로 가는 경로의 길이는 모두 같음.
  - 입력자료는 중복될 수 없음

  

- B+트리 : 데이터의 빠른 접근을 위한 인덱스 역할만 하는 비단말 노드(not leaf)가 추가로 있음

  - B트리를 개선한 트리

### 1 - 11.  자료구조 정리 1



### 1- 12. 자료 구조 정리 2



## 2. Computer architecture

### 2-1.

### 2-2.

### 2-3.

### 2-4.

### 2-5.

















### 2-6. ARM 프로세서

![img](https://t1.daumcdn.net/cfile/tistory/25788C3550CAF8731A)



- ARM : Advanced RISC Machine ( 진보된 _RISC_ 기기)
  
- RISC : Reduced Instruction Set Computing (감소된 명령 집합 컴퓨팅)
  
- 단순한 명령 집합을 가진 프로세서가 복잡한 명령 집합을 가진 프로세서보다 더 효율적이지 않을까?로 탄생
  
- ARM은 칩의 기본 설계 구조만 만들고, 실제 기능 추가와 최적화 부분은 개별 반도체 제조사의 영역으로 맡긴다. 따라서 물리적 설계는 같아도, 명령 집합이 모두 다르기 때문에 서로 다른 칩이 되기도 하는 것이 ARM
  
- 소비자에게는 칩이 논리적 구조인 명령 집합으로 구성되면서, 이런 특성 때문에 물리적 설계 베이스는 같지만 용도에 따라 다양한 제품군을 만날 수 있는 특징이 있다.
  
- 아키텍처는 논리적인 명령 집합을 물리적으로 표현한 것이므로, 명령어가 많고 복잡해질수록 실제 물리적인 칩 구조도 크고 복잡해진다.
  
- 하지만 ARM은 RISC 설계기반으로 단순한 명령집합을 가진 프로세서가 복잡한 것보다 효율적임을 기반하기 때문에 명령집합과 구조 자체가 단순하다. 따라서 ARM기반 프로세서가 더 작고, 효율적이며 상대적으로 느린 것이다.
  
- 단순한 명령 집합은 적은 수의 트랜지스터만 필요하므로 간결한 설계와 더 작은 크기를 가능케 한다. 반도체 기본 부품인 트랜지스터는 전원을 소비해 다이의 크기를 증가시키기 때문에  스마트폰이나 태블릿pc를 위한 프로세서에는 가능한 적은 트랜지스터를 가진 것이 이상적이다.
  
- 따라서 명령 집합의 수가 적기 때문에 트랜지스터 수가 적고 이를 통해 크기가 작고 전원소모가 낮은 ARM CPU가 스마트폰 태블릿pc와 같은 모바일 기기에 많이 사용되고 있다.
  



- 장점
  - 소비자에 있어 ARM은 생태계의 하나라고 생각할 수 있다. ARM을 위해 개발된 프로세서는 오직 ARM프로세서가 탑재된 기기에서만 실행할 수 있다.(x86cpu 프로세서 기반 X)
  - 하나의 ARM기기에 동작하는 OS는 다른 ARM 기반 기기에서도 잘 동작한다.
  - 이러한 이유로 수많은 버전의 안드로이드가 탄생하고, 각종 기기에서 안드로이드가 탑재될 수 있는 가능성이 생김.
- 기업들은 전력 소모를 줄이고 성능을 높이기 위해 설계를 개선하며 노력중이다.



- 특징
  - 레지스터 뱅크 구조: 고속 인터럽트 처리 모드에서 독자적으로 쓸 수 있는 레지스터 뱅크가 있다. 이 특징은 인터럽트를 빠르게 처리하는데 유효하다.
  - 조건부 실행 플래그: 조건분기 명령어와 결합하여 짧은 조건분기 처리에 유효한 특징이다.
  - SP(스택포인터), LR(링크레지스터), PC(프로그램 카운터)가 일반 레지스터에 포함되어 있다. 이 때문에 예외 처리가 타 CPU에 비해 독특해지게 된다.
  - 뱅크당 16개의 레지스터: 통상 RISC 구조의 경우 32개 혹은 그 이상의 일반 레지스터가 있는 경우가 많으나 ARM은 다소 적은 16개의 레지스터만 있다. 게다가 위에서 언급한 SP/LR/PC가 특수 목적 레지스터이므로 실제로 사용 가능한 레지스터 숫자는 13개이다.
  - 배럴 시프트 기능: 명령어 내에서 배럴 시프트 기능을 지정할 수 있다. 타 CPU의 명령어 세트에서는 명령어 두 개로 처리될 내용을 하나의 명령어로 처리할 수 있다.
  - 다중 로드/스토어 명령: 단일 명령으로 여러 레지스터의 로드/스토어를 동시에 제어할 수 있다. 단일 명령어를 1사이클에 처리해야 한다는 RISC 명령어의 원칙에 위배되는 대표적인 명령어이지만 코드 크기 절감과 코드 디코딩 부하 경감(그리고 그로 인한 전력 절감)에 도움이 된다.
  - Thumb 16비트 명령어 세트: ARM이 고성능 컨트롤러 시장을 석권하는데 가장 크게 일조한 특징이자 ARM의 오늘날을 있게 한 특징이다. 일반적인 32비트 크기의 ARM 명령어와는 아예 별도의 16비트 크기의 명령어 세트를 따로 가지고 있다. 명령어 크기가 16비트라고 해도 일반 목적 레지스터 크기는 여전히 32비트이므로 ARM 자체가 32비트인 건 변하지 않는다. Thumb 명령어는 마이크로컨트롤러 제품군에서는 극히 유용하기 때문에 심지어 최신형 Cortex-M 제품군은 Thumb2 명령어만을 지원하게 되었다. 사실 메모리 서브시스템의 속도가 낮거나 실행속도가 별 문제되지 않는 코드의 경우 코드 바이너리 크기를 줄이는 게 유리하기 때문에 고성능 위주의 Cortex-A가 적용된 시스템에서조차도 연산 성능에 민감하지 않은 코드들은 Thumb로 컴파일되었을 정도.
  - Thumb-2 16/32비트 명령어 세트: 위 Thumb의 확장형으로, Thumb의 16비트 크기 명령어에 더해 32비트 크기 명령어가 추가된 형태. 기존의 16비트 Thumb 명령어와 섞어서 쓸 수 있다.
  - 64비트 명령어 세트에서는 상당부분 사라지게 되었다.

  

- ARM은 보통 모바일 기기(스마트폰, 태블릿)같은 저전력을 필요로 하는, 전력대성능비가 중요한 기기들에 자주 사용된다.
- 스마트폰 같은 모바일 기기가 대세가 되면서 크게 성장했다.
- 하지만 ARM 아키텍처라도 성능을 높일수 없는 것은 아니다. 다만 성능을 높이게 되면 그만큼 전력 소모량도 늘어나게 된다.
- 최근 애플의 맥에서 ARM을 전용으로 커스텀한 칩을 쓰면서 (Silicon) 성능이 크게 증가하면서도 전력소모도 챙기면서 훨씬 낮은 전력으로 다른 기기와 동급 성능을 낼 수 있게 되었다.



# OPerating System

## 1. 운영체제란?



## 2. 프로세스와 스레드

프로세스 : 프로그램을 메모리 상에서 실행중인 작업

스레드 : 프로세스 안에서 실행되는 여러 흐름 단위

![img](https://camo.githubusercontent.com/3dc4ad61f03160c310a855a4bd68a9f2a2c9a4c7/68747470733a2f2f74312e6461756d63646e2e6e65742f6366696c652f746973746f72792f393938383931343635433637433330363036)

프로세스는 각각 별도의 주소공간 할당 (독립적)



- code : 코드 자체를 구성하는 메모리 영역 (프로그램 명령)
- Data: 전역변수, 정적 변수, 배열 등
  - 초기화 된 데이터는 data 영역에 저장
  - 초기화 되지 않은 데이터는 bss 영역에 저장
- Heap: 동적 할당 시 사용 ( new(), malloc() 등)
- Stack: 지역변수, 매개변수, 리턴값 (임시 메모리 영역)



스레드는 Stack만 따로 할당 받고 나머지 영역은 서로 공유



하나의 프로세스가 생성될 때, 기본적으로 하나의 스레드 같이 생성

프로세스는 자신만의 고유 공간과 자원을 할당받아 사용하는데 반해, 스레드는 다른 스레드와 공간, 자원을 공유하면서 사용하는 차이가 존재함.



__멀티 프로세스__

하나의 컴퓨터에 여러 CPU 장착 -> 하나 이상의 프로세스들을 동시에 처리 (병렬)

__장점__ : 안전성 ( 메모리 침범 문제를 OS 차원에서 해결)

__단점__ : 각각 독립된 메모리 영역을 갖고 있어, 작업량 많을 수록 오버헤드 발생. Context Switching 으로 인한 성능 저하

__Context Switching__ 이란?

프로세스의 상태 정보를 저장하고 복원하는 일련의 과정

즉, 동작 중인 프로세스가 대기하면서 해당 프로세스의 상태를 보관하고, 대기하고 있던 다음 순번의 프로세스가 동작하면서 이전에 보관했던 프로세스 상태를 복구하는 과정을 말함.

-> 프로세스는 각 독립된 영역을 할당받아 사용되므로, 캐시 메모리 초기화와 같은 무거운 작업이 진행되었을 때 오버헤드가 발생할 문제가 존재함.

__멀티 스레드__

하나의 응용프로그램에서 여러 스레드를 구성해 각 스레드가 하나의 작업을 처리하는 것

스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해줌.

**장점** : 독립적인 프로세스에 비해 공유 메모리만큼의 시간, 자원 손실이 감소 전역 변수와 정적 변수에 대한 자료 공유 가능

**단점** : 안전성 문제. 하나의 스레드가 데이터 공간 망가뜨리면, 모든 스레드가 작동 불능 상태 (공유 메모리를 갖기 때문)

- 멀티스레드의 안전성에 대한 단점은 Critical Section 기법을 통해 대비함

  하나의 스레드가 공유 데이터 값을 변경하는 시점에 다른 스레드가 그 값을 읽으려할 때 발생하는 문제를 해결하기 위한 동기화 과정

  상호 배제, 진행 ,한정된 대기를 충족해야함





## 3. 프로세스 주소 공간



















## 4. 인터럽트(Interrupt)

- 정의
  - 프로그램 을 실행하는 도중에 예기치 않은 상황이 발생할 경우 현재 실행 중인 작업을 즉시 중단하고, 발생된 상황에 대한 우선 처리가 필요함을 CPU에게 알리는 것.
    지금 수행중인 일보다 더 중요한 일(ex: 입출력, 우선 순위 연산 등)이 발생하면 그 일을 먼저 처리하고 나서 하던 일을 계속 해야한다.
  - 외부/내부 인터럽트는 CPU의 하드웨어 신호에 의해 발생
    소프트웨어 인터럽트는 명령어의 수행에 의해 발생
- 외부 인터럽트
  - 입출력 장치, 타이밍 장치, 전원 등 외부적인 요인으로 발생
  - 전원 이상, 기계착오, 외부신호, 입출력
  
- 내부 인터럽트
  - Trap이라고 부르며, 잘못된 명령이나 데이터를 사용할 때 발생
  - 0으로 나누기가 발생, 오버플로우, 명령어를 잘못 사용한 경우(Exception)
  
- 소프트웨어 인터럽트
  - 프로그램 처리 중 명령의 요청에 의해 발생한 것 (SVC 인터럽트)
  - 사용자가 프로그램을 실행시킬 때 발생
  - 소프트웨어 이용 중에 다른 프로세스를 실행시키면 시분할 처리를 위해 자원 할당 동작이 수행된다.



- 우선순위
  1. 전원 공급의 이상
  2. CPU의 기계적 오류
  3. 외부 신호에 의한 인터럽트
  4. 입출력 전송 요청 및 전송완료, 전송 오류
  5. 프로그램 검사 인터럽트
  6. SVC 인터럽트 (수퍼바이저 호출)





- 인터럽트 발생 처리 과정

- <img src="https://mblogthumb-phinf.pstatic.net/20160310_124/scw0531_14575366291105WjS7_PNG/ERTRTETRE.png?type=w2">
- 
  - 주 프로그램이 실행되다가 인터럽트가 발생했다.
  - 현재 수행중인 프로그램을 멈추고, 상태 레지스터와 PC 등을 스택에 잠시 저장한 뒤에 인터럽트 서비스 루틴으로 간다. (잠시 저장하는 이유는 인터럽트 서비스 루틴이 끝난 뒤 다시 원래 작업으로 돌아와야 하기 때문)
  - 만약 인터럽트 기능이 없었다면 컨트롤러는 특정한 어떤 일을 할 시기를 알기 위해 계속 체크를 해야한다. (이를 폴링 Polling 이라고 한다.)
  - 폴링을 하는 시간에는 원래 하던 일에 집중할 수가 없게 되어 많은 기능을 제대로 수행하지 못하는 단점이 있었다.
    

즉 컨트롤러가 입력을 받아들이는 방법(우선순위 판별방법)에는 두가지가 있다.

- 폴링 방식
  - 사용자가 명령어를 사용해 입력 핀의 값을 계속 읽어 변화를 알아내는 방식.
  - 인터럽트 요청 플래그를 차례로 비교하여 우선순위가 가장 높은 인터럽트 자원을 찾아 이에 맞는 인터럽트 서비스 루틴을 수행한다.(하드웨어에 비해 속도 느림)



- 인터럽트 방식

  - MCU 자체가 하드웨어적으로 변화를 체크하여 변화 시에만 일정한 동작을 하는 방식

  - Daisy Chain ( 직렬 연결 방식)

    - 어디에 인터럽트가 발생했는지 확인하는 회로를 직렬로 연결하는 하드웨어적 방법으로 INTR, INTA 선에 장치들을 우선순위에 따라 순서대로 연결하는 방식이라 다른 방법에 비해 구성이 간단하다. 
      그러나 그 단순한 구조 때문에 CPU 가까이 연결된 장치에 비해 멀리있는 장치는 인터럽트 요청이 지연된다.

  - 병렬 우선순위 부여

    - I/O 제어기 마다 별도의 버스 선을 이용 하여 INTR, INTA(INTerrupt acknowledgements)선을 이용해서 확인하는 방법. 이 방법은 인터럽트를 요청한 장치를 쉽게 찾을 수 있는 장점이 있다. 그러나 하드웨어 구성이 매우 복잡하며, CPU가 가지고 있는 인터럽트 포트 수에 의해서 연결할 수 있는 장치의 수가 제한 된다는 점이 단점으로 꼽힌다

    

- 인터럽트 방식은 하드웨어로 지원을 받아야 하는 제약이 있지만, 폴링에 비해 신속하게 대응하는 것이 가능하다. 따라서 실시간 대응이 필요할 때는 필수적인 기능이다.

- 즉 인터럽트는 발생시기를 예측하기 힘든 경우에 컨트롤러가 가장 빠르게 대응할 수 있는 방법이다.



- 인터럽트 요구 레벨

- Windows에서 사용하는 인터럽트 과정으로 위의 인터럽트 우선 순위와 유사하다. 

- 줄여서 IRQL(**I**nterrupt **R**e**q**uest **L**evel)라고 한다.

  IRQL는 0~31으로 구성되어 있으며 아래와 같이 구성되어 있다.

  | 31   | 최고 수준             |
  | ---- | --------------------- |
  | 30   | 전원 이상             |
  | 29   | 프로세서간의 인터럽트 |
  | 28   | Clock                 |
  | 27   | 프로파일              |
  | 3~26 | 장치                  |
  | 2    | 디스패치 (DPC)        |
  | 1    | APC                   |
  | 0    | Passive               |

  
  이 IRQL를 변경할 수 있는 커널 함수는 KeRaiseIrql와 KeLowerIrql이다. 물론 [드라이버](https://namu.wiki/w/드라이버(컴퓨터))에서만 사용할 수 있다. KeRaiseIrql는 IRQL를 높일 때 사용하고 KeLowerIrql는 IRQL를 낮출 때 사용한다. 여기서 KeRaiseIrql를 사용할 때 현재의 IRQL보다 낮게 설정하면 안된다는 것이다. 그럴 경우 [블루스크린](https://namu.wiki/w/블루스크린)이 발생한다. 실제로 KeLowerIrql 내부에서 변경하려는 IRQL 레벨이 현재의 IRQL 레벨보다 낮을 경우 블루스크린을 발생시킨다. 따라서 IRQL를 낮출려면 KeLowerIrql를 사용해야 한다. KeLowerIrql도 변경하려는 IRQL이 현재의 IRQL보다 높을 경우 KeRaiseIrql와 마찬가지로 블루스크린이 발생한다.

  ## [4.](https://namu.wiki/w/인터럽트#toc) 종류













## 5. 시스템 콜(System Call)



## 6. PCB와 Context Switching

### 7. 

### 8.

### 9.

### 10.

### 11.





































### 12. 페이징과 세그먼테이션 Paging , Segmentation

- 기법을 쓰는 이유
  - 다중 프로그래밍 시스템에 여러 프로세스를 수용하기 위해 주기억장치를 동적 분할하는 메모리 관리 작업이 필요하기 때문
- 메모리 관리 기법
  1. 연속 메모리 관리 : 프로그램 전체가 하나의 커다란 공간에 연속적으로 할당되어야 함
     - 고정 분할 기법: 주기억장치가 고정된 파티션으로 분할 (내부 단편화 발생)
     -  동적 분할 기법: 파티션들이 동적 생성되며 자신의 크기와 같은 파티션에 적재 (외부 단편화 발생)
     
  2.  불연속 메모리 관리 : 프로그램의 일부가 서로 다른 주소 공간에 할당될 수 있는 기법
     - 페이지 : 고정 사이즈의 작은 프로세스 조각
     - 프레임 : 페이지 크기와 같은 주기억장치 메모리 조각
     - 단편화 : 기억장치의 빈 공간 or 자료가 여러 조각으로 나뉘는 현상
       ![img](https://user-images.githubusercontent.com/34755287/54821882-d8808080-4ce6-11e9-8ff3-193fa79c04a3.png)
     - 세그먼트 : 서로 다른 크기를 가진 논리적 블록이 연속적 공간에 배치되는 것



- 단순 페이징

- ![img](https://user-images.githubusercontent.com/34755287/54821891-d9191700-4ce6-11e9-98a4-425903e14323.png)

  - 각 프로세스는 프레임들과 같은 길이를 가진 균등 페이지로 나뉨
  - 외부 단편화 X , 소량의 내부 단편화 존재
    

- 단순 세그먼테이션

- ![img](https://user-images.githubusercontent.com/34755287/57119448-47043400-6da5-11e9-95da-91cb808de992.png)

  - 각 프로세스는 여러 세그먼트들로 나뉨
  - 내부 단편화 X, 메모리 사용 효율 개선, 동적 분할을 통한 오버헤드 감소
  - 외부 단편화 존재

  

- 내부단편화, 외부단편화?



- 가상 메모리 페이징

  - 단순 페이징과 비교해 프로세스 페이지 전부를 로드시킬 필요 X
  - 필요한 페이지가 있으면 나중에 자동으로 불러들어짐
  - 외부 단편화 x , 복잡한 메모리 관리로 오버헤드 발생

  

- 가상 메모리 세그먼테이션

  - 필요하지 않은 세그먼트들은 로드되지 않음
  - 필요한 세그먼트 있을 때 나중에 자동으로 불러들어짐
  - 내부단편화 X , 복잡한 메모리 관리로 오버헤드 발생



























